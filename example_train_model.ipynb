{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\123\\Desktop\\torch cuda\\.venv\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
            "  warnings.warn(\"No audio backend is available.\")\n",
            "c:\\Users\\123\\Desktop\\torch cuda\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from ssd.utils_ssd300 import dboxes300_coco\n",
        "from ssd.create_model import nvidia_ssd\n",
        "from ssd.utils_ssd300 import Encoder\n",
        "from ssd.model import Loss, SSD300\n",
        "from ssd.SSD_Transformers import SSDTransformer\n",
        "from utils.utils import set_seed\n",
        "from train_model import train_model\n",
        "from ssd.model_eval import model_evaluate\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from config.config import Configs\n",
        "from ssd.model_eval import model_evaluate\n",
        "\n",
        "from ssd.decode_results import Processing as processing\n",
        "from ssd.loader_crowdhuman import CrowdHuman\n",
        "\n",
        "from tqdm.auto import tqdm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = 'cuda'\n",
        "ssd_300 = nvidia_ssd(device=device, pretrainded_custom=False, pretrained_default=True)\n",
        "\n",
        "feat_ext_w = ssd_300.feature_extractor.state_dict()\n",
        "\n",
        "model = SSD300(label_num=3)\n",
        "model = model.cuda()\n",
        "\n",
        "model.feature_extractor.load_state_dict(feat_ext_w)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load annotation file:  data\\annotation_train.json\n",
            "load annotation file:  data\\annotation_val.json\n",
            "load annotation file:  data\\annotation_test.json\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "device = \"cuda\"\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in model.feature_extractor.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "dboxes = dboxes300_coco()\n",
        "encoder = Encoder(dboxes)\n",
        "\n",
        "loss_func = Loss(dboxes, device=device)\n",
        "transformers_ssd_train = SSDTransformer(dboxes, size=(300, 300), val=False)\n",
        "transformers_ssd_val = SSDTransformer(dboxes, size=(300, 300), val=True)\n",
        "set_seed()\n",
        "data_train = CrowdHuman(\n",
        "    img_folder=\"data\\\\train\\\\\",\n",
        "    annotate_file=\"data\\\\annotation_train.json\",\n",
        "    transform=transformers_ssd_train,\n",
        "    use_head_bbx=True,\n",
        ")\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    data_train,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True \n",
        ")\n",
        "\n",
        "\n",
        "data_val = CrowdHuman(\n",
        "    img_folder=\"data\\\\val\\\\\",\n",
        "    annotate_file=\"data\\\\annotation_val.json\",\n",
        "    transform=transformers_ssd_val,\n",
        "    use_head_bbx=True,\n",
        ")\n",
        "\n",
        "val_dataloader = DataLoader(\n",
        "    data_val,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,  \n",
        ")\n",
        "\n",
        "\n",
        "data_test = CrowdHuman(\n",
        "    img_folder=\"data\\\\test\\\\\",\n",
        "    annotate_file=\"data\\\\annotation_test.json\",\n",
        "    transform=transformers_ssd_val,\n",
        "    use_head_bbx=True,\n",
        ")\n",
        "\n",
        "test_dataloader = DataLoader(\n",
        "    data_test,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,  \n",
        ")\n",
        "\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.Adam(params, lr=0.001)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer=optimizer, patience=4,threshold = 1e-3, verbose=True, factor=0.5, mode = 'max'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ckpt = torch.load('weight\\\\state best_model_at_adam2.pth')\n",
        "\n",
        "ckpt = ckpt[\"model\"]\n",
        "model.load_state_dict(ckpt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 47/47 [01:28<00:00,  1.89s/it]\n"
          ]
        }
      ],
      "source": [
        "print(\"Evaluating\")\n",
        "loss_sum = 0\n",
        "l1 =  Loss(dboxes, device=device)\n",
        "for i, data in enumerate(tqdm(val_dataloader, total=len(val_dataloader))):\n",
        "    model.eval()\n",
        "    img, _, images_sizes, bbox_data, bbox_labels = data\n",
        "    with torch.no_grad():\n",
        "        ploc, plabel = model(img.to(device))\n",
        "    new_bbox_data = []\n",
        "    new_bbox_labels = []\n",
        "    for i in zip(bbox_data, bbox_labels ):\n",
        "        bbox_ = i[0][i[1] != 0]\n",
        "        label_ = i[1][i[1] != 0]\n",
        "        bbox, label = encoder.encode(bbox_, label_)\n",
        "        new_bbox_data.append(bbox)\n",
        "        new_bbox_labels.append(label)\n",
        "    \n",
        "    new_bbox_data = torch.stack(new_bbox_data, dim= 0)\n",
        "    new_bbox_labels = torch.stack(new_bbox_labels, dim= 0)\n",
        "    \n",
        "    gloc = Variable(new_bbox_data.transpose(1, 2).contiguous(), requires_grad=False).to(\n",
        "            device)\n",
        "    glabel = Variable(new_bbox_labels, requires_grad=False).to(device)\n",
        "\n",
        "    loss = l1(ploc=ploc, plabel=plabel, gloc=gloc, glabel=glabel)\n",
        "    loss_sum += loss.item()       \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.7407786947615604"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss_sum / len(val_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
