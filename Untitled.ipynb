{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "534fd838",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from config.config import Configs\n",
        "from pycocotools.coco import COCO\n",
        "import json\n",
        "import cv2\n",
        "from ssd.utils_ssd300 import dboxes300_coco\n",
        "from ssd.train_loader import  CocoDataReader\n",
        "from ssd.utils_ssd300 import calc_iou_tensor\n",
        "from ssd.create_model import nvidia_ssd\n",
        "from ssd.utils_ssd300 import Encoder\n",
        "from ssd.model import Loss\n",
        "from ssd.SSD_Transformers import SSDTransformer\n",
        "\n",
        "from utils.utils import SSDTransformer\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "9a61a747",
      "metadata": {},
      "outputs": [],
      "source": [
        "#for param_name, param in model.named_parameters():\n",
        "   #if param_name.endswith(\".bias\"):\n",
        "        #print(param_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ffd3d514",
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "\n",
        "\n",
        "\n",
        "model = nvidia_ssd()\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "    \n",
        "for param in model.feature_extractor.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "dboxes = dboxes300_coco()\n",
        "encoder = Encoder(dboxes)\n",
        "\n",
        "\n",
        "loss_func = Loss(dboxes)\n",
        "\n",
        "transformers_ssd_train = SSDTransformer(dboxes, size=(300, 300), val=False)\n",
        "annotate_file = 'COCOdata\\\\annotations\\\\instances_val2017.json'\n",
        "data_reader = CocoDataReader(\n",
        "                    img_folder='COCOdata\\\\val2017\\\\',\n",
        "                    annotate_file=annotate_file,\n",
        "                    transform=transformers_ssd_train )\n",
        "\n",
        "train_dataloader = DataLoader(data_reader ,\n",
        "                                batch_size=batch_size,\n",
        "                                shuffle=True,  # Note: distributed sampler is shuffled :(\n",
        "                             )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for nbatch, data in enumerate(train_dataloader):\n",
        "    \n",
        "    #optimizer.zero_grad()\n",
        "    \n",
        "    img, img_id, images_sizes,  bbox_data, bbox_labels = data\n",
        "    \n",
        "    gloc = Variable(bbox_data.transpose(1, 2).contiguous(), requires_grad=False)\n",
        "    glabel = Variable(bbox_labels, requires_grad=False)\n",
        "    \n",
        "    ploc, plabel = model(img)\n",
        "    loss = loss_func(ploc=ploc, plabel=plabel, gloc=gloc, glabel=glabel ) \n",
        "    \n",
        "    break\n",
        "\n",
        "    https://www.kaggle.com/code/billiemage/understand-lr-scheduler-with-simple-examples\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "32078740",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor(3.9616, grad_fn=<MeanBackward1>)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89ed46e9",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f13ad885",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fc99de6",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "315ee657",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 4, 8732])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ploc.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "f8e47ac0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 81, 8732])"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "plabel.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17566512",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c54be24",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "8e738626",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([189, 600, 426, 437]), tensor([197, 227, 640, 183])]"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "images_sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "688226c1",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([404484, 263644,  43816, 412286])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "92dcf175",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[[0.0133, 0.0133, 0.0700, 0.0700],\n",
              "         [0.0400, 0.0133, 0.0700, 0.0700],\n",
              "         [0.0667, 0.0133, 0.0700, 0.0700],\n",
              "         ...,\n",
              "         [0.5000, 0.5000, 0.9558, 0.9558],\n",
              "         [0.5000, 0.5000, 1.0000, 0.6152],\n",
              "         [0.5000, 0.5000, 0.6152, 1.0000]],\n",
              "\n",
              "        [[0.0133, 0.0133, 0.0700, 0.0700],\n",
              "         [0.0400, 0.0133, 0.0700, 0.0700],\n",
              "         [0.0667, 0.0133, 0.0700, 0.0700],\n",
              "         ...,\n",
              "         [0.5000, 0.5000, 0.9558, 0.9558],\n",
              "         [0.5000, 0.5000, 1.0000, 0.6152],\n",
              "         [0.5000, 0.5000, 0.6152, 1.0000]],\n",
              "\n",
              "        [[0.0133, 0.0133, 0.0700, 0.0700],\n",
              "         [0.0400, 0.0133, 0.0700, 0.0700],\n",
              "         [0.0667, 0.0133, 0.0700, 0.0700],\n",
              "         ...,\n",
              "         [0.5000, 0.5000, 0.9558, 0.9558],\n",
              "         [0.5000, 0.5000, 1.0000, 0.6152],\n",
              "         [0.5000, 0.5000, 0.6152, 1.0000]],\n",
              "\n",
              "        [[0.0133, 0.0133, 0.0700, 0.0700],\n",
              "         [0.0400, 0.0133, 0.0700, 0.0700],\n",
              "         [0.0667, 0.0133, 0.0700, 0.0700],\n",
              "         ...,\n",
              "         [0.5000, 0.5000, 0.9558, 0.9558],\n",
              "         [0.5000, 0.5000, 1.0000, 0.6152],\n",
              "         [0.5000, 0.5000, 0.6152, 1.0000]]])"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "bbox_sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "b7e86108",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[tensor([189, 600, 426, 437]), tensor([197, 227, 640, 183])]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "images_sizes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb727376",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "215ee4b9",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "39809b52",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "2e6eb95d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 3, 300, 300])"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27f40293",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f83f0e0",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e08e118",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "38ff19bd",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
              "        [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
              "        [2.2489, 2.2489, 2.2489,  ..., 2.2489, 2.2489, 2.2489],\n",
              "        ...,\n",
              "        [1.7180, 1.8037, 1.8722,  ..., 2.0777, 2.0948, 2.0948],\n",
              "        [1.6324, 1.8208, 1.9064,  ..., 2.0777, 2.0948, 2.0948],\n",
              "        [1.5982, 1.8379, 1.8722,  ..., 2.0948, 2.0777, 2.0777]])"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i[0][0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "094b9c07",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.7591,  0.7933,  0.8789,  ...,  1.6153,  1.5639,  1.6495],\n",
              "        [ 0.7762,  0.7762,  0.8276,  ...,  1.5125,  1.4783,  1.4783],\n",
              "        [ 0.1597,  0.2282,  0.2796,  ...,  1.4098,  1.3755,  1.3070],\n",
              "        ...,\n",
              "        [-1.7754, -1.6213, -1.7240,  ..., -1.1589, -1.1247, -1.0048],\n",
              "        [-1.8782, -1.6727, -1.6384,  ..., -1.2788, -1.1075, -0.9705],\n",
              "        [-1.9124, -1.8782, -1.6555,  ..., -1.2788, -1.1075, -1.1075]])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "i[0][2][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cac7eaa",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1d17f3ae",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f0c940a8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---loading model weights and saving to ssd folder--- \n",
            "---loading model complete--- \n"
          ]
        }
      ],
      "source": [
        "model = nvidia_ssd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f780affc",
      "metadata": {},
      "outputs": [],
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "    \n",
        "for param in model.feature_extractor.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1b5151a",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "074f024c",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa53045b",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f9dbf669",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<generator object Module.parameters at 0x000002097D8A37B0>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.feature_extractor.parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "70732601",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "70377a55",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<utils.utils.SSDTransformer at 0x269ad2b5ca0>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datareader.transform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "019f219a",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82847c07",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "aa6ab315",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Compose(\n",
              "    Resize(size=(300, 300), interpolation=bilinear, max_size=None, antialias=warn)\n",
              "    ColorJitter(brightness=(0.875, 1.125), contrast=(0.5, 1.5), saturation=(0.5, 1.5), hue=(-0.05, 0.05))\n",
              "    ToTensor()\n",
              ")"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "transformers_ssd_train.img_trans"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f0f8d7b",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "dfb3da2e",
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "np.random.seed(seed=0)\n",
        "\n",
        "\n",
        "dboxes = dboxes300_coco()\n",
        "\n",
        "encoder = Encoder(dboxes)\n",
        "    #print(dboxes.dboxes.shape) # \u0441\u043e\u0437\u0434\u0430\u043b \u0434\u0435\u0444\u043e\u043b\u0442\u043d\u044b\u0435 bbx [8732, 4]\n",
        "annotate_file = 'COCOdata\\\\annotations\\\\instances_val2017.json'\n",
        "datareader = CocoDataReader(\n",
        "        img_folder='COCOdata\\\\val2017\\\\',\n",
        "        annotate_file=annotate_file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa938856",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e40bbf4",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "b496fe73",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---loading model weights and saving to ssd folder--- \n",
            "---loading model complete--- \n"
          ]
        }
      ],
      "source": [
        "model = nvidia_ssd(\n",
        "        pretrained_default=True,\n",
        "        pretrainded_custom=False,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12c6098e",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4edc25a4",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "379aa012",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "2dcdb1c2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "72\n"
          ]
        }
      ],
      "source": [
        "configs = Configs()\n",
        "torch.manual_seed(configs.random_seed)\n",
        "np.random.seed(seed=configs.random_seed)\n",
        "    #cocoGt =  get_coco_ground_truth()\n",
        "    #print(cocoGt) # coco \u0430\u043d\u043d\u043e\u0442\u0430\u0446\u0438\u0438, \u043f\u043e\u043a\u0430 \u0440\u0435\u0448\u0438\u043b \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u0432\u0441\u0435 \u043a\u0430\u043a \u0432 \u0438\u0441\u0445\u043e\u0434\u043d\u0438\u043a\u0435\n",
        "    \n",
        "dboxes_class = dboxes300_coco()\n",
        "    #print(dboxes.dboxes.shape) # \u0441\u043e\u0437\u0434\u0430\u043b \u0434\u0435\u0444\u043e\u043b\u0442\u043d\u044b\u0435 bbx [8732, 4]\n",
        "annotate_file = 'COCOdata\\\\annotations\\\\instances_val2017.json'\n",
        "datareader = CocoDataReader(\n",
        "img_folder='COCOdata\\\\val2017\\\\',\n",
        "annotate_file=annotate_file)\n",
        "    \n",
        "    #print(datareader.img_keys)\n",
        "    \n",
        "     #input ltrb format, output xywh format\n",
        "img, img_id, size_image, bbox_sizes, bbox_labels = datareader[0]\n",
        "\n",
        "\n",
        "dboxes_xywh = dboxes_class(order=\"xywh\").unsqueeze(dim=0)\n",
        "dboxes = dboxes_class(\"ltrb\")\n",
        "nboxes = dboxes.size(0)\n",
        "scale_xy = dboxes_class.scale_xy\n",
        "scale_wh = dboxes_class.scale_wh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "25060682",
      "metadata": {},
      "outputs": [],
      "source": [
        "ious = calc_iou_tensor(bbox_sizes, dboxes) # [n_boxes, 8732]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "2984b85b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8732])"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " criteria = 0.5\n",
        "\n",
        "best_dbox_ious, best_dbox_idx  = ious.max(dim =0) # \u0432\u044b\u0434\u0430\u0435\u0442 \u043d\u043e\u043c\u0435\u0440\u0430 (\u0441\u0442\u0440\u043e\u043a) \u0431\u0431\u043e\u0445, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u043d\u0430\u0431\u0438\u043b\u0435\u0435 \u044e\u043b\u0438\u0437\u043a\u0438 \u043a \u044f\u043a\u043e\u0440\u043d\u044b\u043c, \u043c\u0430\u0441\u0441\u0438\u0432 \u0440\u0430\u0437\u043c\u0435\u0440\u0430 8732\n",
        "\n",
        "best_bbox_ious, best_bbox_idx = ious.max(dim = 1) # \u043d\u043e\u043c\u0435\u0440 (\u0441\u0442\u043e\u043b\u0431\u0446\u043e\u0432) \u044f\u043a\u043e\u0440\u043d\u044b\u0445 \u0431\u0431\u0445, \u0431\u043b\u0438\u0437\u043a\u0438\u0445 \u043a \u043f\u0435\u0440\u0435\u0434\u0430\u043d\u043d\u044b\u043c \u0440\u0430\u0437\u043c\u0435\u0440 \u043c\u0430\u0441\u0441\u0438\u0432\u0430 19 \n",
        "\n",
        "#best_bbox_idx = \u043d\u043e\u043c\u0435\u0440\u0430 \u0441\u0442\u043e\u043b\u0431\u0446\u043e\u0432, \u0432 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u043c\u0430\u043a\u0441\u0438\u043c\u0443\u043c \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0439 \u0438\u0437 \u0441\u0442\u0440\u043e\u043a!!!! \u0442.\u0435. \u043f\u0435\u0440\u0432\u043e\u0435 \u0447\u0438\u0441\u043b\u043e - \u043c\u0430\u043a\u0441\u0438\u043c\u0443\u043c \u0432 \u043f\u0435\u0440\u0432\u043e\u0439 \u0441\u0442\u0440\u043e\u043a\u0435\n",
        "\n",
        "# \u043f\u043e\u043c\u0435\u0449\u0430\u0435\u043c \u043c\u0430\u043a\u0441\u0438\u043c\u0443\u043c ious =2  \u043d\u0430 \u0442\u0435 \u043f\u043e\u0437\u0438\u0446\u0438\u0438 \u0441\u0442\u0440\u043e\u043a, \u0434\u043b\u044f \u043a\u043e\u0442\u043e\u0440\u044b\u0445 axis =1 \u0438\u043c\u0435\u0435\u0442 \u043c\u0430\u043a\u0441\u0438\u043c\u0443\u043c ()\n",
        "best_dbox_ious.index_fill_(0, best_bbox_idx, 2.0)\n",
        "\n",
        "idx = torch.arange(0, best_bbox_idx.size(0), dtype=torch.int64)# \u0442.\u043a. \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0439 \u0441\u0442\u0440\u043e\u043a\u0438 \u043c\u044b \u043d\u0430\u0448\u043b\u0438 \u043c\u0430\u043a\u0441\u0438\u043c\u0443\u043c, \u0442\u043e \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u043f\u043e\u043b\u043e\u0436\u0438\u0442\u044c \u043d\u043e\u043c\u0435\u0440\u0430 \u0441\u0442\u0440\u043e\u043a \u0432 \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e\u043c \u043f\u043e\u0440\u044f\u0434\u043a\u0435\n",
        "best_dbox_idx[best_bbox_idx[idx]] = idx #  \u043c\u0430\u043a\u0441\u0438\u043c\u0443\u043c\u044b \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0439 \u0438\u0437 \u0441\u0442\u0440\u043e\u043a!!!! \u0442.\u0435. \u043f\u0435\u0440\u0432\u043e\u0435 \u0447\u0438\u0441\u043b\u043e - \u043c\u0430\u043a\u0441\u0438\u043c\u0443\u043c \u0432 \u043f\u0435\u0440\u0432\u043e\u0439 \u0441\u0442\u0440\u043e\u043a\u0435\n",
        "masks = best_dbox_ious > criteria\n",
        "labels_out = torch.zeros(nboxes, dtype=torch.long)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "best_dbox_idx.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb0bb0fa",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efff6664",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "25c5c024",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11,  5,  3,  5,  7, 16,  5,\n",
              "        18])"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labelsbest_dbox_idx[best_bbox_idx[idx]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "e042be05",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([5219, 8558, 8488, 5214, 2663, 2475, 6310, 2357, 5289, 5291,  579,  389,\n",
              "        3881, 5177, 3881, 3841, 6348, 3881, 6685])"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_bbox_idx "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "e278b52c",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
              "        2.])"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_dbox_ious[best_bbox_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "ca65d7a0",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 17, 13, 17, 15, 16, 17,\n",
              "        18])"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_dbox_idx[best_bbox_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12cf03f7",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "b782448a",
      "metadata": {},
      "outputs": [],
      "source": [
        "a = best_dbox_idx.clone().detach()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "360a3e24",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "d578a741",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8732])"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_dbox_ious.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "19e00c11",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ 389,  579, 2357, 2475, 2663, 3841, 3881, 5177, 5214, 5219, 5289, 5291,\n",
              "        6310, 6348, 6685, 8488, 8558])"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_bbox_idx.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "b7449863",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([8732])"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_dbox_idx.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7279016d",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
