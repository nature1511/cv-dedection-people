{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\123\\Desktop\\torch cuda\\.venv\\lib\\site-packages\\torchaudio\\backend\\utils.py:74: UserWarning: No audio backend is available.\n",
            "  warnings.warn(\"No audio backend is available.\")\n",
            "c:\\Users\\123\\Desktop\\torch cuda\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from ssd.utils_ssd300 import dboxes300_coco\n",
        "from ssd.create_model import nvidia_ssd\n",
        "from ssd.utils_ssd300 import Encoder\n",
        "from ssd.model import Loss, SSD300\n",
        "from ssd.SSD_Transformers import SSDTransformer\n",
        "from utils.utils import set_seed\n",
        "from train_model import train_model\n",
        "\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from config.config import Configs\n",
        "\n",
        "from ssd.decode_results import Processing as processing\n",
        "from ssd.loaser_crowdhuman import CrowdHuman\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "device = 'cuda'\n",
        "ssd_300 = nvidia_ssd(device=device, pretrainded_custom=False, pretrained_default=True)\n",
        "\n",
        "feat_ext_w = ssd_300.feature_extractor.state_dict()\n",
        "\n",
        "model = SSD300(label_num=3)\n",
        "model = model.cuda()\n",
        "\n",
        "model.feature_extractor.load_state_dict(feat_ext_w)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "load annotation file:  data\\annotation_train.json\n",
            "load annotation file:  data\\annotation_val.json\n",
            "Adjusting learning rate of group 0 to 2.6000e-03.\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "device = \"cuda\"\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for param in model.feature_extractor.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "dboxes = dboxes300_coco()\n",
        "encoder = Encoder(dboxes)\n",
        "\n",
        "loss_func = Loss(dboxes, device=device)\n",
        "transformers_ssd_train = SSDTransformer(dboxes, size=(300, 300), val=False)\n",
        "transformers_ssd_val = SSDTransformer(dboxes, size=(300, 300), val=True)\n",
        "set_seed()\n",
        "data_train = CrowdHuman(\n",
        "    img_folder=\"data\\\\train\\\\\",\n",
        "    annotate_file=\"data\\\\annotation_train.json\",\n",
        "    transform=transformers_ssd_train,\n",
        "    use_head_bbx=True,\n",
        ")\n",
        "\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    data_train,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True \n",
        ")\n",
        "\n",
        "\n",
        "data_val = CrowdHuman(\n",
        "    img_folder=\"data\\\\val\\\\\",\n",
        "    annotate_file=\"data\\\\annotation_val.json\",\n",
        "    transform=transformers_ssd_val,\n",
        "    use_head_bbx=True,\n",
        ")\n",
        "\n",
        "val_dataloader = DataLoader(\n",
        "    data_val,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,  \n",
        ")\n",
        "\n",
        "\n",
        "# https://www.kaggle.com/code/billiemage/understand-lr-scheduler-with-simple-examples\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "optimizer = torch.optim.SGD(params, lr=2.6e-3, momentum=0.9, nesterov=True)\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(\n",
        "    optimizer=optimizer, step_size=15, gamma=0.1, verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "EPOCH 1 of 60\n",
            "Training\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 235/235 [08:38<00:00,  2.20s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluating\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 47/47 [04:24<00:00,  5.64s/it]\n",
            "c:\\Users\\123\\Desktop\\torch cuda\\.venv\\lib\\site-packages\\torchmetrics\\utilities\\prints.py:42: UserWarning: Encountered more than 100 detections in a single image. This means that certain detections with the lowest scores will be ignored, that may have an undesirable impact on performance. Please consider adjusting the `max_detection_threshold` to suit your use case. To disable this warning, set attribute class `warn_on_many_detections=False`, after initializing the metric.\n",
            "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch #1 train loss: 5.812\n",
            "Epoch #1 mAP: 0.08791942894458771\n",
            "Epoch #1 mAP_50: 0.26362788677215576\n",
            "Epoch #1 best mAP: 0.08791942894458771 at epoch = 0\n",
            "Took 14.111 minutes for epoch 0\n",
            "Adjusting learning rate of group 0 to 2.6000e-03.\n",
            "\n",
            "EPOCH 2 of 60\n",
            "Training\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  5%|\u258d         | 11/235 [00:21<07:13,  1.94s/it]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_model(\n\u001b[0;32m      2\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m      3\u001b[0m     encoder \u001b[39m=\u001b[39;49m encoder,\n\u001b[0;32m      4\u001b[0m     num_epoch\u001b[39m=\u001b[39;49m\u001b[39m60\u001b[39;49m,\n\u001b[0;32m      5\u001b[0m     optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[0;32m      6\u001b[0m     loss_func \u001b[39m=\u001b[39;49m loss_func,\n\u001b[0;32m      7\u001b[0m     train_dataloader \u001b[39m=\u001b[39;49m train_dataloader,\n\u001b[0;32m      8\u001b[0m     val_dataloader \u001b[39m=\u001b[39;49m val_dataloader,\n\u001b[0;32m      9\u001b[0m     device  \u001b[39m=\u001b[39;49m device,\n\u001b[0;32m     10\u001b[0m     scheduler\u001b[39m=\u001b[39;49mscheduler,\n\u001b[0;32m     11\u001b[0m     path_to_save\u001b[39m=\u001b[39;49mConfigs\u001b[39m.\u001b[39;49mpath_to_save_state_model,\n\u001b[0;32m     12\u001b[0m     use_pick_best\u001b[39m=\u001b[39;49mConfigs\u001b[39m.\u001b[39;49muse_pick_best_in_eval\n\u001b[0;32m     13\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\123\\Desktop\\torch cuda\\train_model.py:30\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, encoder, num_epoch, optimizer, loss_func, train_dataloader, val_dataloader, device, scheduler, path_to_save, use_pick_best)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mEPOCH \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m of \u001b[39m\u001b[39m{\u001b[39;00mnum_epoch\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     29\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m---> 30\u001b[0m losses \u001b[39m=\u001b[39m train_one_loop(\n\u001b[0;32m     31\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m     32\u001b[0m     optimizer\u001b[39m=\u001b[39;49moptimizer,\n\u001b[0;32m     33\u001b[0m     loss_func\u001b[39m=\u001b[39;49mloss_func,\n\u001b[0;32m     34\u001b[0m     train_dataloader\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[0;32m     35\u001b[0m     device\u001b[39m=\u001b[39;49mdevice,\n\u001b[0;32m     36\u001b[0m )\n\u001b[0;32m     37\u001b[0m metrics_map \u001b[39m=\u001b[39m model_evaluate(\n\u001b[0;32m     38\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[0;32m     39\u001b[0m     encoder\u001b[39m=\u001b[39mencoder,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     42\u001b[0m     use_pick_best\u001b[39m=\u001b[39muse_pick_best,\n\u001b[0;32m     43\u001b[0m )\n\u001b[0;32m     45\u001b[0m cur_map \u001b[39m=\u001b[39m metrics_map[\u001b[39m\"\u001b[39m\u001b[39mmap\u001b[39m\u001b[39m\"\u001b[39m]\n",
            "File \u001b[1;32mc:\\Users\\123\\Desktop\\torch cuda\\ssd\\train_one_loop.py:9\u001b[0m, in \u001b[0;36mtrain_one_loop\u001b[1;34m(model, optimizer, loss_func, train_dataloader, device)\u001b[0m\n\u001b[0;32m      7\u001b[0m loss_sum \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m      8\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m----> 9\u001b[0m \u001b[39mfor\u001b[39;00m data \u001b[39min\u001b[39;00m tqdm(train_dataloader, total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(train_dataloader)):\n\u001b[0;32m     10\u001b[0m     \u001b[39m# for nbatch, data in enumerate(train_dataloader):\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     i \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     12\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n",
            "File \u001b[1;32mc:\\Users\\123\\Desktop\\torch cuda\\.venv\\lib\\site-packages\\tqdm\\std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1183\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\123\\Desktop\\torch cuda\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    631\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    632\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 633\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    634\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    635\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    636\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    637\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[1;32mc:\\Users\\123\\Desktop\\torch cuda\\.venv\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    675\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    676\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 677\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    678\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    679\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
            "File \u001b[1;32mc:\\Users\\123\\Desktop\\torch cuda\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[1;32mc:\\Users\\123\\Desktop\\torch cuda\\.venv\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
            "File \u001b[1;32mc:\\Users\\123\\Desktop\\torch cuda\\ssd\\loaser_crowdhuman.py:74\u001b[0m, in \u001b[0;36mCrowdHuman.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     71\u001b[0m bbox_labels \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(target)\n\u001b[0;32m     72\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     73\u001b[0m     img, (htot, wtot), bbox_sizes, bbox_labels \u001b[39m=\u001b[39m \\\n\u001b[1;32m---> 74\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img, (htot, wtot), bbox_sizes, bbox_labels)\n\u001b[0;32m     76\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     77\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\123\\Desktop\\torch cuda\\ssd\\SSD_Transformers.py:173\u001b[0m, in \u001b[0;36mSSDTransformer.__call__\u001b[1;34m(self, img, img_size, bbox, label, max_num)\u001b[0m\n\u001b[0;32m    170\u001b[0m     label_out[:label\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)] \u001b[39m=\u001b[39m label\n\u001b[0;32m    171\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrans_val(img), img_size, bbox_out, label_out\n\u001b[1;32m--> 173\u001b[0m img, img_size, bbox, label \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcrop(img, img_size, bbox, label)\n\u001b[0;32m    174\u001b[0m img, bbox \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhflip(img, bbox)\n\u001b[0;32m    176\u001b[0m img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_trans(img)\u001b[39m.\u001b[39mcontiguous()\n",
            "File \u001b[1;32mc:\\Users\\123\\Desktop\\torch cuda\\ssd\\SSD_Transformers.py:80\u001b[0m, in \u001b[0;36mSSDCropping.__call__\u001b[1;34m(self, img, img_size, bboxes, labels)\u001b[0m\n\u001b[0;32m     77\u001b[0m right \u001b[39m=\u001b[39m left \u001b[39m+\u001b[39m w\n\u001b[0;32m     78\u001b[0m bottom \u001b[39m=\u001b[39m top \u001b[39m+\u001b[39m h\n\u001b[1;32m---> 80\u001b[0m ious \u001b[39m=\u001b[39m calc_iou_tensor(bboxes, torch\u001b[39m.\u001b[39;49mtensor(\n\u001b[0;32m     81\u001b[0m     [[left, top, right, bottom]]))\n\u001b[0;32m     83\u001b[0m \u001b[39m# tailor all the bboxes and return\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m ((ious \u001b[39m>\u001b[39m min_iou) \u001b[39m&\u001b[39m (ious \u001b[39m<\u001b[39m max_iou))\u001b[39m.\u001b[39mall():\n",
            "File \u001b[1;32mc:\\Users\\123\\Desktop\\torch cuda\\ssd\\utils_ssd300.py:40\u001b[0m, in \u001b[0;36mcalc_iou_tensor\u001b[1;34m(box1, box2)\u001b[0m\n\u001b[0;32m     37\u001b[0m intersect \u001b[39m=\u001b[39m delta[:, :, \u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m delta[:, :, \u001b[39m1\u001b[39m]\n\u001b[0;32m     38\u001b[0m \u001b[39m# *mask1.float()*mask2.float()\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m delta1 \u001b[39m=\u001b[39m be1[:, :, \u001b[39m2\u001b[39;49m:] \u001b[39m-\u001b[39;49m be1[:, :, :\u001b[39m2\u001b[39;49m]\n\u001b[0;32m     41\u001b[0m area1 \u001b[39m=\u001b[39m delta1[:, :, \u001b[39m0\u001b[39m] \u001b[39m*\u001b[39m delta1[:, :, \u001b[39m1\u001b[39m]\n\u001b[0;32m     42\u001b[0m delta2 \u001b[39m=\u001b[39m be2[:, :, \u001b[39m2\u001b[39m:] \u001b[39m-\u001b[39m be2[:, :, :\u001b[39m2\u001b[39m]\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "train_model(\n",
        "    model=model,\n",
        "    encoder = encoder,\n",
        "    num_epoch=60,\n",
        "    optimizer=optimizer,\n",
        "    loss_func = loss_func,\n",
        "    train_dataloader = train_dataloader,\n",
        "    val_dataloader = val_dataloader,\n",
        "    device  = device,\n",
        "    scheduler=scheduler,\n",
        "    path_to_save=Configs.path_to_save_state_model,\n",
        "    use_pick_best=Configs.use_pick_best_in_eval\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
